{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "from torchrl_development.envs.sampling.context_space_sampling import sample_context_space\n",
    "from torchrl_development.utils.configuration import make_serializable\n",
    "import json\n",
    "from find_load_threshold import find_load_threshold\n",
    "import numpy as np\n",
    "from torchrl_development.envs.env_generators import make_env, parse_env_json\n",
    "from context_set_stats import plot_lta_histogram, plot_arrival_rate_histogram\n",
    "from datetime import datetime\n",
    "from generate_context_set import sample_contexts_hit_and_run, sample_contexts_dilkins, create_context_set_dict\n",
    "base_name = \"SH4b\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T16:05:20.876540200Z",
     "start_time": "2024-05-16T16:05:09.830154500Z"
    }
   },
   "id": "6313e835a46dda84"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Find Correct Load Factor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d3b789a7725001e"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURR_FILE_PATH: C:\\Users\\Jerrod\\PycharmProjects\\GDRL4Nets\\torchrl_development\\envs\n",
      "TORCHRL_DEVELOPMENT_PATH: C:\\Users\\Jerrod\\PycharmProjects\\GDRL4Nets\\torchrl_development\n",
      "CONFIG_FILE_PATH: C:\\Users\\Jerrod\\PycharmProjects\\GDRL4Nets\\torchrl_development\\config\\environments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing LTA for sampled contexts:   0%|          | 0/50 [2:17:47<?, ?it/s]\n",
      "100%|██████████| 10/10 [02:24<00:00, 14.45s/it, load=1.7, trial=0]\n"
     ]
    }
   ],
   "source": [
    "load_range = np.linspace(1.4, 1.7, 10)\n",
    "env_params = parse_env_json(f\"{base_name}.json\")\n",
    "load_range, final_lta_backlogs, admissible_count =find_load_threshold(env_params, load_range, repeats = 1, seed=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T14:52:30.152972300Z",
     "start_time": "2024-05-16T14:50:05.599186700Z"
    }
   },
   "id": "f7c6ca76aeafce84"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sample from the Context Space"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f8e0c1bf669c9df"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURR_FILE_PATH: C:\\Users\\Jerrod\\PycharmProjects\\GDRL4Nets\\torchrl_development\\envs\n",
      "TORCHRL_DEVELOPMENT_PATH: C:\\Users\\Jerrod\\PycharmProjects\\GDRL4Nets\\torchrl_development\n",
      "CONFIG_FILE_PATH: C:\\Users\\Jerrod\\PycharmProjects\\GDRL4Nets\\torchrl_development\\config\\environments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      "Admissible/Sampled environments: 0/0:   0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      "Admissible/Sampled environments: 0/0:   5%|▌         | 1/20 [01:09<22:01, 69.53s/it]\u001B[A\n",
      "Admissible/Sampled environments: 1/1:   5%|▌         | 1/20 [01:09<22:01, 69.53s/it]\u001B[A\n",
      "Admissible/Sampled environments: 1/1:  10%|█         | 2/20 [02:21<21:16, 70.92s/it]\u001B[A\n",
      "Admissible/Sampled environments: 2/2:  10%|█         | 2/20 [02:21<21:16, 70.92s/it]\u001B[A\n",
      "Admissible/Sampled environments: 2/2:  15%|█▌        | 3/20 [03:22<18:47, 66.33s/it]\u001B[A\n",
      "Admissible/Sampled environments: 3/3:  15%|█▌        | 3/20 [03:22<18:47, 66.33s/it]\u001B[A\n",
      "Admissible/Sampled environments: 3/3:  20%|██        | 4/20 [04:39<18:47, 70.50s/it]\u001B[A\n",
      "Admissible/Sampled environments: 4/4:  20%|██        | 4/20 [04:39<18:47, 70.50s/it]\u001B[A\n",
      "Admissible/Sampled environments: 4/4:  25%|██▌       | 5/20 [05:46<17:19, 69.27s/it]\u001B[A\n",
      "Admissible/Sampled environments: 5/5:  25%|██▌       | 5/20 [05:46<17:19, 69.27s/it]\u001B[A\n",
      "Admissible/Sampled environments: 5/5:  30%|███       | 6/20 [06:53<16:02, 68.73s/it]\u001B[A\n",
      "Admissible/Sampled environments: 6/6:  30%|███       | 6/20 [06:53<16:02, 68.73s/it]\u001B[A\n",
      "Admissible/Sampled environments: 6/6:  35%|███▌      | 7/20 [08:01<14:49, 68.39s/it]\u001B[A\n",
      "Admissible/Sampled environments: 7/7:  35%|███▌      | 7/20 [08:01<14:49, 68.39s/it]\u001B[A\n",
      "Admissible/Sampled environments: 7/7:  35%|███▌      | 7/20 [08:06<14:49, 68.39s/it]\u001B[A\n",
      "Admissible/Sampled environments: 7/7:  40%|████      | 8/20 [09:09<13:40, 68.36s/it]\u001B[A\n",
      "Admissible/Sampled environments: 8/8:  40%|████      | 8/20 [09:09<13:40, 68.36s/it]\u001B[A\n",
      "Admissible/Sampled environments: 8/8:  45%|████▌     | 9/20 [10:12<12:12, 66.61s/it]\u001B[A\n",
      "Admissible/Sampled environments: 9/9:  45%|████▌     | 9/20 [10:12<12:12, 66.61s/it]\u001B[A\n",
      "Admissible/Sampled environments: 9/9:  50%|█████     | 10/20 [11:09<10:37, 63.72s/it]\u001B[A\n",
      "Admissible/Sampled environments: 10/10:  50%|█████     | 10/20 [11:09<10:37, 63.72s/it]\u001B[A\n",
      "Admissible/Sampled environments: 10/10:  55%|█████▌    | 11/20 [12:09<09:20, 62.32s/it]\u001B[A\n",
      "Admissible/Sampled environments: 11/11:  55%|█████▌    | 11/20 [12:09<09:20, 62.32s/it]\u001B[A\n",
      "Admissible/Sampled environments: 11/11:  60%|██████    | 12/20 [13:15<08:29, 63.68s/it]\u001B[A\n",
      "Admissible/Sampled environments: 12/12:  60%|██████    | 12/20 [13:15<08:29, 63.68s/it]\u001B[A\n",
      "Admissible/Sampled environments: 12/12:  65%|██████▌   | 13/20 [14:19<07:25, 63.66s/it]\u001B[A\n",
      "Admissible/Sampled environments: 13/13:  65%|██████▌   | 13/20 [14:19<07:25, 63.66s/it]\u001B[A\n",
      "Admissible/Sampled environments: 13/13:  65%|██████▌   | 13/20 [14:31<07:25, 63.66s/it]\u001B[A\n",
      "Admissible/Sampled environments: 13/13:  70%|███████   | 14/20 [15:35<06:44, 67.34s/it]\u001B[A\n",
      "Admissible/Sampled environments: 14/14:  70%|███████   | 14/20 [15:35<06:44, 67.34s/it]\u001B[A\n",
      "Admissible/Sampled environments: 14/14:  75%|███████▌  | 15/20 [16:31<05:19, 63.98s/it]\u001B[A\n",
      "Admissible/Sampled environments: 15/15:  75%|███████▌  | 15/20 [16:31<05:19, 63.98s/it]\u001B[A\n",
      "Admissible/Sampled environments: 15/15:  75%|███████▌  | 15/20 [16:35<05:19, 63.98s/it]\u001B[A\n",
      "Admissible/Sampled environments: 15/15:  80%|████████  | 16/20 [17:30<04:10, 62.55s/it]\u001B[A\n",
      "Admissible/Sampled environments: 16/16:  80%|████████  | 16/20 [17:30<04:10, 62.55s/it]\u001B[A\n",
      "Admissible/Sampled environments: 16/16:  85%|████████▌ | 17/20 [18:32<03:06, 62.15s/it]\u001B[A\n",
      "Admissible/Sampled environments: 17/17:  85%|████████▌ | 17/20 [18:32<03:06, 62.15s/it]\u001B[A\n",
      "Admissible/Sampled environments: 17/17:  90%|█████████ | 18/20 [19:38<02:07, 63.50s/it]\u001B[A\n",
      "Admissible/Sampled environments: 18/18:  90%|█████████ | 18/20 [19:38<02:07, 63.50s/it]\u001B[A\n",
      "Admissible/Sampled environments: 18/18:  95%|█████████▌| 19/20 [20:47<01:05, 65.01s/it]\u001B[A\n",
      "Admissible/Sampled environments: 19/19:  95%|█████████▌| 19/20 [20:47<01:05, 65.01s/it]\u001B[A\n",
      "Admissible/Sampled environments: 19/19: 100%|██████████| 20/20 [21:46<00:00, 63.24s/it]\u001B[A\n",
      "Getting non-dominated (key) rates: 100%|██████████| 20/20 [21:46<00:00, 65.31s/it]     \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sampled environments: 20\n",
      "Number of admissible rates: 19\n",
      "Saved multi_env_params to SH4b_lf1.4_context_space-nondominated.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Manually Select load factor based on above results\n",
    "load_factor = 1.4\n",
    "\n",
    "# Settings for the sampling loop\n",
    "num_admissible_envs = 20\n",
    "num_rollouts_per_env = 1\n",
    "rollout_steps =  50_000\n",
    "keep_dominated = False\n",
    "\n",
    "# File Loading and Saving\n",
    "base_param_file = \"SH4b.json\"\n",
    "if keep_dominated:\n",
    "    save_path = f\"{base_param_file.split('.')[0]}_lf{load_factor}_context_space.json\"\n",
    "else:\n",
    "    save_path = f\"{base_param_file.split('.')[0]}_lf{load_factor}_context_space-nondominated.json\"\n",
    "# check if save_path exists, if so, then add a number to the end of the file\n",
    "if os.path.exists(save_path):\n",
    "    i = 1\n",
    "    while os.path.exists(f\"{save_path.split('.')[1]}_{i}.json\"):\n",
    "        i += 1\n",
    "    save_path = f\"{save_path.split('.')[1]}_{i}.json\"\n",
    "\n",
    "# Sample the environment parameters\n",
    "context_space_dict = sample_context_space(base_param_file,\n",
    "                                       num_admissible_envs,\n",
    "                                       num_rollouts_per_env,\n",
    "                                       rollout_steps,\n",
    "                                       keep_dominated=False,\n",
    "                                       load_factor=load_factor,  #1.32\n",
    "                                       terminal_backlog=1000,\n",
    "                                       add_borders=True)\n",
    "\n",
    "\n",
    "serial_context_dictionary = make_serializable(context_space_dict)\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(serial_context_dictionary, f)\n",
    "print(f\"Saved multi_env_params to {save_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T15:15:18.816280400Z",
     "start_time": "2024-05-16T14:53:32.323422200Z"
    }
   },
   "id": "aa802881fba1e1b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting information on the context space vertices"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39f37686b099fc2f"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Load the context space dictionary\n",
    "# save_path = \"SH4_lf1.5_context_space-nondominated.json\"\n",
    "with open(save_path, \"r\") as f:\n",
    "    context_space_dict = json.load(f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T20:31:49.772649800Z",
     "start_time": "2024-04-10T20:31:49.713795400Z"
    }
   },
   "id": "a065cbd22b6181ef"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Change settings so plots are generated a pop up window not using Qt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('TkAgg')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T12:26:18.788482Z",
     "start_time": "2024-05-16T12:26:18.690992500Z"
    }
   },
   "id": "1d64a18c3cd8cd5d"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "ltas = context_space_dict[\"ltas\"]\n",
    "arrival_rates = np.array([context_space_dict[\"context_dicts\"][str(i)][\"arrival_rates\"] for i in range(context_space_dict[\"num_envs\"])])\n",
    "network_loads = context_space_dict[\"network_loads\"]\n",
    "# plot histogram of ltas\n",
    "plot_lta_histogram(ltas)\n",
    "plot_arrival_rate_histogram(arrival_rates)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T15:16:36.562684800Z",
     "start_time": "2024-05-16T15:16:35.702983100Z"
    }
   },
   "id": "a05b070cf00995bd"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "eb5362bfe3be91c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now create many samples from the context space"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8e92f2f1cb8275a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hit and Run Sampling\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'context_space_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 15\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sampling_method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhit_and_run\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStarting Hit and Run Sampling\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 15\u001B[0m     context_samples \u001B[38;5;241m=\u001B[39m sample_contexts_hit_and_run(\u001B[43mcontext_space_dict\u001B[49m, num_contexts, thin \u001B[38;5;241m=\u001B[39m thin)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     context_samples \u001B[38;5;241m=\u001B[39m sample_contexts_dilkins(context_space_dict, num_contexts)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'context_space_dict' is not defined"
     ]
    }
   ],
   "source": [
    "num_contexts = 20\n",
    "thin = 1000\n",
    "sampling_method = 'hit_and_run' #'dilkins' or 'hit_and_run'\n",
    "date_time = datetime.now().strftime('%m%d%H%M')\n",
    "\n",
    "# create folder to store all the sampled context parameters and context set dictionary\n",
    "folder_name = f\"{base_name}_sampled_contexts_{num_contexts}_{sampling_method}_{date_time}\"\n",
    "# if folder doesn't exist, create it\n",
    "if not os.path.exists(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "param_save_file = f\"{base_name}_sampled_context_parameters_{num_contexts}_{sampling_method}_{date_time}.json\"\n",
    "context_set_dict_file_name = f\"{base_name}_context_set_{num_contexts}_{date_time}.json\"\n",
    "if sampling_method == 'hit_and_run':\n",
    "    print(\"Starting Hit and Run Sampling\")\n",
    "    context_samples = sample_contexts_hit_and_run(context_space_dict, num_contexts, thin = thin)\n",
    "else:\n",
    "    context_samples = sample_contexts_dilkins(context_space_dict, num_contexts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T16:05:23.078570700Z",
     "start_time": "2024-05-16T16:05:22.771723900Z"
    }
   },
   "id": "7eeacb04f00f1d38"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "## Plot the histogram of the context samples\n",
    "import matplotlib.pyplot as plt\n",
    "# change so it plots to a white background, but I don't have seaborn-white\n",
    "# print(plt.style.available)\n",
    "plot_arrival_rate_histogram(context_samples, title = f\"{sampling_method} Sampling Parameters Histogram\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T15:17:16.752252800Z",
     "start_time": "2024-05-16T15:17:15.816761800Z"
    }
   },
   "id": "31b056c50c3dc79f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create Context Set Dictionary"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c734114831471e4"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_context_set_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 10\u001B[0m\n\u001B[0;32m      1\u001B[0m make_env_params \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobserve_lambda\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m      2\u001B[0m                            \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseed\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m      3\u001B[0m                            \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mterminal_backlog\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      7\u001B[0m                            \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mterminate_on_convergence\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m      8\u001B[0m                            \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconvergence_threshold\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m0.01\u001B[39m}\n\u001B[1;32m---> 10\u001B[0m context_set_dict \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_context_set_dict\u001B[49m(context_samples,\n\u001B[0;32m     11\u001B[0m                                                    context_space_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontext_dicts\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menv_params\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     12\u001B[0m                                                    make_env_params)\n\u001B[0;32m     13\u001B[0m serial_context_set_dictionary \u001B[38;5;241m=\u001B[39m make_serializable(context_set_dict)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(folder_name, context_set_dict_file_name), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n",
      "\u001B[1;31mNameError\u001B[0m: name 'create_context_set_dict' is not defined"
     ]
    }
   ],
   "source": [
    "make_env_params = {\"observe_lambda\": False,\n",
    "                           \"seed\": None,\n",
    "                           \"terminal_backlog\": None,\n",
    "                           \"observation_keys\": [\"Q\", \"Y\"],\n",
    "                           \"inverse_reward\": False,\n",
    "                           \"stat_window_size\": 100000,\n",
    "                           \"terminate_on_convergence\": False,\n",
    "                           \"convergence_threshold\": 0.01}\n",
    "\n",
    "context_set_dict = create_context_set_dict(context_samples,\n",
    "                                                   context_space_dict[\"context_dicts\"][\"0\"][\"env_params\"],\n",
    "                                                   make_env_params)\n",
    "serial_context_set_dictionary = make_serializable(context_set_dict)\n",
    "with open(os.path.join(folder_name, context_set_dict_file_name), \"w\") as f:\n",
    "     json.dump(serial_context_set_dictionary, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T16:05:01.046826100Z",
     "start_time": "2024-05-16T16:05:00.212373800Z"
    }
   },
   "id": "5b011ec0162da3bb"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e814e1a75e1eae01"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "context_set_dict = json.load(open(\"SH3_sampled_contexts_100_dikins_03251626/SH3_context_set_100_03251626.json\", \"r\"))\n",
    "context_set_dict = json.load(open(\"SH2u_context_set_100_03211523.json\", \"r\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T20:58:05.869004300Z",
     "start_time": "2024-03-25T20:58:05.531017200Z"
    }
   },
   "id": "273719d89472db6f"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "ltas = context_set_dict[\"ltas\"]\n",
    "arrival_rates = np.array([context_set_dict[\"context_dicts\"][i][\"arrival_rates\"] for i in range(context_set_dict[\"num_envs\"])])\n",
    "network_loads = context_set_dict[\"network_loads\"]\n",
    "# plot histogram of ltas\n",
    "plot_lta_histogram(ltas)\n",
    "plot_arrival_rate_histogram(arrival_rates)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T14:46:57.064892900Z",
     "start_time": "2024-05-16T14:46:55.930510900Z"
    }
   },
   "id": "8439dafc7f294596"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3aec8aa2f56a6efc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
