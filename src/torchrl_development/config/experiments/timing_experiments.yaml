# Global
seed: 531997
device: cpu

# agent
agent:
  temperature: 1.0

# environment
env:
  terminal_backlog: 100

# collector per env
collector:
  total_training_frames: 40960
  frames_per_batch: 4096
  frame_skip: 1

# eval
eval:
  eval_interval: 20480
  num_eval_envs: 1
  traj_steps: 50000


# logger
logger:
  backend: wandb
  project_name: single_hop_trl2
  group_name: null
  run_name: ["scaled_lambda", "PPO"]


# Optim
optim:
  lr:  3.0e-4
  eps: 1.0e-6
  weight_decay: 0.0
  max_grad_norm: 1.0
  anneal_lr: True
  clip_epsilon: False
  alpha: 0.99

# loss
loss:
  gamma: 0.99
  mini_batch_size: 64
  ppo_epochs: 3
  gae_lambda: 0.95
  clip_epsilon: 0.2
  anneal_clip_epsilon: False
  critic_coef: 1.0
  entropy_coef: 0.00
  loss_critic_type: l2
  norm_advantage: False
